# MedGemma-only Phase 0 run â€” 20 pairs
phase: 0
description: "20-pair MedGemma-only benchmark"

data:
  source: huggingface
  fixture_path: data/hf_cache/trialgpt_criterion_annotations.json
  dataset_id: "ncbi/TrialGPT-Criterion-Annotations"
  split: train
  n_pairs: 20
  sampling: stratified
  seed: 42

models:
  - name: medgemma-1.5-4b
    provider: huggingface
    model_id: google/medgemma-1-5-4b-it-hae
    max_concurrent: 1

baselines:
  - name: gpt4-precomputed
    source: dataset

evaluation:
  tier: phase0
  granularity: criterion_level
  ingest_source: gold
  timeout_seconds: 300
  metrics:
    - accuracy
    - f1_macro
    - f1_met_not_met
    - cohens_kappa
    - confusion_matrix
    - evidence_overlap

budget:
  max_cost_usd: 5.0
  warn_at_usd: 3.0

output:
  run_dir: "runs/"
  save_reasoning_chains: true
  save_raw_responses: true
  save_evidence_sentences: true
