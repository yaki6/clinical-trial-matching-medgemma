{
  "medgemma_4b": {
    "n_cases": 10,
    "diagnosis_exact_match": 0.0,
    "diagnosis_substring_match": 0.0,
    "diagnosis_llm_judge_correct": 0.0,
    "diagnosis_llm_judge_partial": 0.1,
    "findings_rouge_recall_mean": 0.106532016164343,
    "findings_rouge_precision_mean": 0.10407790318318558,
    "findings_rouge_fmeasure_mean": 0.074111874946418,
    "avg_latency_ms": 38560.26130828541,
    "total_cost_usd": 0.17322
  },
  "gemini_pro": {
    "n_cases": 10,
    "diagnosis_exact_match": 0.0,
    "diagnosis_substring_match": 0.2,
    "diagnosis_llm_judge_correct": 0.4,
    "diagnosis_llm_judge_partial": 0.0,
    "findings_rouge_recall_mean": 0.28730434600994614,
    "findings_rouge_precision_mean": 0.1012931429211386,
    "findings_rouge_fmeasure_mean": 0.12609521249722927,
    "avg_latency_ms": 12293.448274885304,
    "total_cost_usd": 0.0567275
  }
}